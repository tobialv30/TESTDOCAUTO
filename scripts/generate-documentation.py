#!/usr/bin/env python3
"""
Generador autom√°tico de documentaci√≥n Salesforce usando Claude API
Push a GitHub ‚Üí An√°lisis con Claude ‚Üí Crear/Actualizar Confluence
Version 3.0 - Super Complete Documentation + Consistent Naming
"""

import os
import sys
import json
import requests
import base64
from pathlib import Path
import re
from typing import Dict, List, Optional, Tuple
import hashlib

# SUPER PROMPT COMPLETO - Basado en el original pero sin interacci√≥n
SUPER_DOCUMENTATION_PROMPT = """Eres un Consultor Salesforce Senior especializado en crear documentaci√≥n t√©cnica integral, visual y completa que cualquier desarrollador o administrador pueda entender inmediatamente.

üéØ CONTEXTO Y OBJETIVO
Analiza COMPLETAMENTE todos los componentes Salesforce proporcionados y genera documentaci√≥n t√©cnica DEFINITIVA y EXHAUSTIVA. NO hagas preguntas. NO solicites informaci√≥n adicional. Genera documentaci√≥n completa basada √öNICAMENTE en los archivos proporcionados, aplicando tu expertise en Salesforce para llenar cualquier gap con mejores pr√°cticas est√°ndar.

üèóÔ∏è ESTRUCTURA DE DOCUMENTACI√ìN REQUERIDA

# [Nombre del Componente Principal]

## üéØ Presentaci√≥n Ejecutiva
**¬øQu√© hace?** [Explicaci√≥n clara en 2 l√≠neas m√°ximo]
**¬øPara qui√©n?** [Usuarios finales espec√≠ficos]  
**¬øPor qu√© es importante?** [Valor de negocio concreto]
**Tipo de Componente:** [LWC/Apex/Flow/Object/etc.]
**Criticidad:** üî¥ Cr√≠tico / üü° Importante / üü¢ Informativo
**Versi√≥n Salesforce:** Spring '25 (o inferir del c√≥digo)

## üìä Inventario de Componentes
[Genera tabla visual con TODOS los archivos encontrados]

| Componente | Tipo | Criticidad | Prop√≥sito | Dependencias |
|------------|------|-----------|-----------|---------------|
| [Nombre] | [Tipo] | üî¥/üü°/üü¢ | [Funci√≥n espec√≠fica] | [Lista componentes] |

**Leyenda:**
- üî¥ **Cr√≠tico:** Afecta operaciones core del negocio
- üü° **Importante:** Impacta flujos de trabajo importantes  
- üü¢ **Informativo:** Mejora experiencia de usuario

## üèóÔ∏è Arquitectura General

```mermaid
graph TB
    A[Usuario] -->|Interact√∫a| B[Lightning App]
    B -->|Ejecuta| C[Componente Principal]
    C -->|Llama| D[Dependencias]
    D -->|Integra| E[Sistemas Externos]
    E -->|Responde| D
    D -->|Actualiza| F[Salesforce Records]
```

## üì¶ An√°lisis Detallado de Componentes

### [Para CADA componente encontrado - NO omitas ninguno]

#### üìã [Tipo_Componente - Nombre]
**üìç Ubicaci√≥n:** `ruta/completa/del/archivo`
**üéØ Prop√≥sito:** [Funci√≥n espec√≠fica y detallada]
**üîó Relaciones:** [Con qu√© otros componentes se relaciona]
**üìä Tama√±o:** [L√≠neas de c√≥digo/tama√±o del archivo]

**üìù An√°lisis L√≠nea por L√≠nea:**
[Explica las partes m√°s importantes del c√≥digo, l√≠nea por l√≠nea]

**‚ö° Funcionalidades Clave:**
- [Lista todas las funciones/m√©todos principales]
- [Explica qu√© hace cada uno]
- [Par√°metros que recibe]
- [Qu√© devuelve]

**üîß Configuraci√≥n T√©cnica:**
- [Propiedades @api si es LWC]
- [Decoradores si es Apex]
- [Configuraciones XML]
- [Permisos requeridos]

**‚ö†Ô∏è Validaciones y Reglas:**
- [Validaciones implementadas]
- [Reglas de negocio aplicadas]
- [Manejo de errores]

## üîÑ Flujos y Procesos

### [Si hay Flows]
‚ö° **[Nombre del Flow]**
- **Tipo:** [Record-Triggered/Screen/Scheduled/etc.]
- **Objeto:** [Objeto que dispara]
- **Disparador:** [Before/After Save/etc.]
- **Prop√≥sito:** [Qu√© automatiza espec√≠ficamente]

**üìã Diagrama de Flujo:**
```mermaid
flowchart TD
    Start([Trigger Event]) --> Check{Criteria Met?}
    Check -->|Yes| Process[Process Records]
    Check -->|No| End([End])
    Process --> Update[Update Fields]
    Update --> Notify[Send Notifications]
    Notify --> End
```

**üîç L√≥gica Detallada:**
1. **Criterios de Entrada:** [Condiciones espec√≠ficas]
2. **Variables:** [Qu√© se calcula y c√≥mo]
3. **Decisiones:** [L√≥gica de branching completa]
4. **Acciones:** [Operaciones ejecutadas paso a paso]
5. **Manejo de Errores:** [Qu√© pasa si algo falla]

## üíª C√≥digo Apex Detallado

### [Para cada clase Apex]
üèõÔ∏è **[ClassName.cls]**
**üéØ Prop√≥sito:** [Qu√© problema resuelve espec√≠ficamente]
**üèóÔ∏è Patr√≥n de Dise√±o:** [Singleton/Handler/Utility/Controller/etc.]
**üîó Dependencias:** [Otras clases que usa]

```apex
// C√≥digo completo con comentarios explicativos
[Incluir el c√≥digo completo aqu√≠ con explicaciones]
```

**üìä M√©todos Principales:**
- `methodName()`: [Descripci√≥n completa, par√°metros, retorno]
- `anotherMethod()`: [Descripci√≥n completa, par√°metros, retorno]

**üß™ Test Coverage:**
- **Clase Test:** [Nombre de la clase test]
- **Coverage:** [Porcentaje estimado]
- **Escenarios Cubiertos:** [Lista casos de prueba]

**üö® Exception Handling:**
- [C√≥mo maneja errores]
- [Tipos de excepciones capturadas]
- [Logging implementado]

## ‚ö° Lightning Web Components

### [Para cada LWC]
üé® **[componentName]**
**üéØ Prop√≥sito:** [Qu√© interfaz proporciona exactamente]
**üìç Ubicaci√≥n:** [D√≥nde se usa en Salesforce]
**üì± Responsive:** [S√≠/No y consideraciones m√≥viles]

**üèóÔ∏è Estructura de Archivos:**
```
componentName/
‚îú‚îÄ‚îÄ componentName.html       // UI Structure & Template
‚îú‚îÄ‚îÄ componentName.js         // Logic & Event Handling  
‚îú‚îÄ‚îÄ componentName.css        // Styling & Visual Design
‚îî‚îÄ‚îÄ componentName.js-meta.xml // Metadata & Configuration
```

**‚öôÔ∏è Propiedades y Eventos:**

| Prop/Event | Tipo | Descripci√≥n | Ejemplo de Uso |
|------------|------|-------------|----------------|
| recordId | @api String | ID del registro actual | '0015000000XXXXX' |
| onSuccess | CustomEvent | Se dispara al guardar | {detail: {id: 'xxx'}} |

**üîÑ Lifecycle Hooks:**
- `connectedCallback()`: [Qu√© inicializa]
- `disconnectedCallback()`: [Cleanup que hace]
- `renderedCallback()`: [Operaciones post-render]

**üì° Interacci√≥n con Apex:**
- **M√©todos llamados:** [Lista de @AuraEnabled methods]
- **Datos intercambiados:** [Qu√© se env√≠a y recibe]
- **Error Handling:** [C√≥mo maneja errores de Apex]

**üé® Estilos CSS:**
[Analiza los estilos principales y su prop√≥sito]

## üîó Integraciones y APIs

### [Para cada integraci√≥n]
üåê **[Sistema Externo]**
**üéØ Prop√≥sito:** [Qu√© datos sincroniza y por qu√© exactamente]
**‚è∞ Frecuencia:** [Tiempo real/batch/scheduled con detalles]
**üö® Criticidad:** üî¥/üü°/üü¢

**üìä Diagrama de Secuencia:**
```mermaid
sequenceDiagram
    participant SF as Salesforce
    participant EXT as Sistema Externo
    SF->>SF: Trigger detecta cambio
    SF->>EXT: POST /api/endpoint
    EXT-->>SF: 200 OK + Data
    SF->>SF: Actualiza registros
    SF->>SF: Log resultado
```

**üó∫Ô∏è Mapeo de Datos Completo:**

| Campo Salesforce | Campo Externo | Transformaci√≥n | Requerido | Validaci√≥n |
|------------------|---------------|----------------|-----------|------------|
| Account.Name | company_name | Ninguna | ‚úÖ | Max 80 chars |
| Account.Revenue__c | annual_revenue | String ‚Üí Decimal | ‚ùå | > 0 |

**üîß Configuraci√≥n T√©cnica:**
- **Endpoint:** [URL completa]
- **Autenticaci√≥n:** [M√©todo usado]
- **Headers:** [Headers requeridos]
- **Rate Limits:** [Limitaciones conocidas]

**‚ö†Ô∏è Manejo de Errores Completo:**
- **Timeout (30s):** [Proceso de retry autom√°tico]
- **Auth Failure:** [Reautenticaci√≥n y reintentos]
- **Invalid Data:** [Validaciones aplicadas]
- **Network Issues:** [Fallback strategies]

## üîí Seguridad y Permisos

**üë• Permission Sets Requeridos:**
- **[PermissionSet_Name]**: [Descripci√≥n completa de permisos]
  - Object Permissions: [CRUD espec√≠ficos]
  - Field Level Security: [Campos y niveles]
  - System Permissions: [APIs, features]
  - Custom Permissions: [Permissions customizados]

**üõ°Ô∏è Field Level Security:**

| Campo | Read | Edit | Admin Only | Justificaci√≥n |
|-------|------|------|------------|---------------|
| Sensitive_Field__c | Admin | Admin | ‚úÖ | Datos financieros confidenciales |
| Status__c | All Users | Manager+ | ‚ùå | Control de workflow |

**üîê Sharing y Visibility:**
- [OWD settings]
- [Sharing Rules aplicables]
- [Role hierarchy considerations]

## üì± Experiencia de Usuario

**üéØ User Journey Completo:**
1. **Punto de Entrada:** [C√≥mo llega el usuario al componente]
2. **Interacciones:** [Pasos que realiza el usuario]
3. **Validaciones:** [Qu√© validaciones ve]
4. **Confirmaciones:** [Mensajes de √©xito/error]
5. **Siguiente Paso:** [A d√≥nde va despu√©s]

**üìä Casos de Uso Principales:**
- **Caso de Uso 1:** [Escenario detallado]
- **Caso de Uso 2:** [Escenario detallado]
- **Casos Edge:** [Situaciones l√≠mite]

## ‚ö†Ô∏è Troubleshooting y Mantenimiento

### üîß Problemas Comunes y Soluciones

| Problema | S√≠ntomas | Causa M√°s Probable | Soluci√≥n Paso a Paso | Prevention |
|----------|-----------|-------------------|---------------------|------------|
| Component no carga | Pantalla blanca | Permisos faltantes | 1. Verificar Permission Set<br/>2. Asignar al usuario<br/>3. Refrescar p√°gina | Documentar permisos requeridos |
| Flow no ejecuta | Records no se procesan | Criterios de entrada incorrectos | 1. Debug Flow Builder<br/>2. Verificar criterios<br/>3. Probar con record test | Usar naming conventions claros |

### üìä Debug y Logging

**Para Flows:**
```
Setup ‚Üí Debug Logs ‚Üí New ‚Üí Workflow and Flow = FINEST
Ejecutar proceso ‚Üí Revisar logs ‚Üí Buscar "FLOW_START"
```

**Para Apex:**
```apex
System.debug(LoggingLevel.INFO, 'Debug: Processing recordId: ' + recordId);
System.debug(LoggingLevel.ERROR, 'Error: ' + e.getMessage());
```

**Para LWC:**
```javascript
console.log('Component loaded:', this.recordId);
console.error('Error occurred:', error);
```

### üìà Monitoreo y Performance

**üîç M√©tricas Clave:**
- **Response Time:** [Tiempo esperado]
- **Error Rate:** [Tasa aceptable]
- **Usage Statistics:** [C√≥mo medir adoption]

**‚ö° Optimizaciones Implementadas:**
- [Lista optimizaciones de performance]
- [Caching strategies]
- [Query optimizations]

## üîÑ DevOps y Deployment

**üì¶ Componentes a Deployar:**
```xml
<!-- Package.xml para deployment -->
<?xml version="1.0" encoding="UTF-8"?>
<Package xmlns="http://soap.sforce.com/2006/04/metadata">
    <types>
        <members>[ComponentName]</members>
        <name>[ComponentType]</name>
    </types>
    <version>59.0</version>
</Package>
```

**üß™ Testing Strategy:**
1. **Unit Tests:** [Coverage m√≠nimo 75%]
2. **Integration Tests:** [Pruebas end-to-end]
3. **UAT:** [User acceptance testing]

**üöÄ Deployment Checklist:**
- [ ] Unit tests passing
- [ ] Permission sets updated
- [ ] Documentation updated
- [ ] Backup completed
- [ ] Rollback plan ready

## üìä Informaci√≥n del Documento

**üìã Metadatos:**
- **√öltima Actualizaci√≥n:** [FECHA_ACTUAL]
- **Versi√≥n:** [VERSION]
- **Autor:** Generado autom√°ticamente por Claude API
- **Pr√≥xima Revisi√≥n:** [FECHA_ACTUAL + 3 meses]

**üìù Componentes Documentados:**
[LISTA_COMPONENTES_DETALLADA]

**üîÑ Historial de Cambios:**

| Versi√≥n | Fecha | Cambios Realizados | Impacto |
|---------|-------|-------------------|---------|
| 1.0 | [FECHA_ACTUAL] | Documentaci√≥n inicial completa | N/A |

**üéØ Pr√≥ximos Pasos Recomendados:**
1. [Implementar mejoras identificadas]
2. [Optimizaciones sugeridas]
3. [Funcionalidades adicionales]

---

**‚ö†Ô∏è IMPORTANTE PARA EL AN√ÅLISIS:**
Documenta CADA archivo encontrado, no omitas ning√∫n componente. Si un archivo parece incompleto o tiene errores, documenta los issues encontrados y sugiere correcciones. Aplica tu conocimiento de Salesforce para inferir contexto cuando falte informaci√≥n espec√≠fica."""

class SuperSalesforceDocumentationGenerator:
    def __init__(self):
        self.anthropic_api_key = os.getenv('ANTHROPIC_API_KEY')
        self.atlassian_email = os.getenv('ATLASSIAN_EMAIL')
        self.atlassian_api_token = os.getenv('ATLASSIAN_API_TOKEN')
        self.atlassian_base_url = os.getenv('ATLASSIAN_BASE_URL')
        self.confluence_space_key = os.getenv('CONFLUENCE_SPACE_KEY')
        
        if not all([self.anthropic_api_key, self.atlassian_email, 
                   self.atlassian_api_token, self.atlassian_base_url, 
                   self.confluence_space_key]):
            print("‚ùå ERROR: Variables de entorno faltantes")
            sys.exit(1)

    def analyze_salesforce_repository(self) -> Dict:
        """Analiza el repositorio y extrae informaci√≥n COMPLETA de componentes Salesforce"""
        repo_structure = {}
        
        # Patrones m√°s completos de archivos Salesforce
        patterns = {
            'apex_classes': ['**/*.cls'],
            'apex_triggers': ['**/*.trigger'],
            'flows': ['**/*.flow-meta.xml'],
            'lwc_components': {
                'html': '**/lwc/**/*.html',
                'js': '**/lwc/**/*.js', 
                'css': '**/lwc/**/*.css',
                'xml': '**/lwc/**/*.js-meta.xml'
            },
            'aura_components': {
                'cmp': '**/aura/**/*.cmp',
                'js_controller': '**/aura/**/*Controller.js',
                'js_helper': '**/aura/**/*Helper.js',
                'css': '**/aura/**/*.css'
            },
            'visualforce': ['**/*.page', '**/*.component'],
            'objects': ['**/*.object-meta.xml'],
            'fields': ['**/*.field-meta.xml'],
            'permission_sets': ['**/*.permissionset-meta.xml'],
            'profiles': ['**/*.profile-meta.xml'],
            'custom_metadata': ['**/*.md-meta.xml'],
            'custom_labels': ['**/*.labels-meta.xml'],
            'static_resources': ['**/*.resource-meta.xml'],
            'email_templates': ['**/*.email-meta.xml'],
            'reports': ['**/*.report-meta.xml'],
            'dashboards': ['**/*.dashboard-meta.xml'],
            'workflow_rules': ['**/*.workflow-meta.xml'],
            'validation_rules': ['**/*.validation-meta.xml']
        }
        
        # Funci√≥n para procesar archivos normales
        def process_files(pattern_list, component_type):
            files_found = []
            for pattern in pattern_list:
                for file_path in Path('.').glob(pattern):
                    try:
                        with open(file_path, 'r', encoding='utf-8') as f:
                            content = f.read()
                        files_found.append({
                            'path': str(file_path),
                            'content': content,
                            'size': len(content),
                            'lines': len(content.splitlines())
                        })
                    except Exception as e:
                        print(f"‚ö†Ô∏è Error leyendo {file_path}: {e}")
            return files_found

        # Funci√≥n para procesar componentes con subtipos (LWC, Aura)
        def process_component_files(component_patterns, component_type):
            components = {}
            for subtype, pattern in component_patterns.items():
                for file_path in Path('.').glob(pattern):
                    # Extraer nombre del componente del path
                    component_name = self.extract_component_name(file_path, component_type)
                    
                    if component_name not in components:
                        components[component_name] = {}
                    
                    try:
                        with open(file_path, 'r', encoding='utf-8') as f:
                            content = f.read()
                        components[component_name][subtype] = {
                            'path': str(file_path),
                            'content': content,
                            'size': len(content),
                            'lines': len(content.splitlines())
                        }
                    except Exception as e:
                        print(f"‚ö†Ô∏è Error leyendo {file_path}: {e}")
            return components

        # Procesar cada tipo de componente
        for component_type, pattern_config in patterns.items():
            if isinstance(pattern_config, dict):
                # Componentes con subtipos (LWC, Aura)
                components = process_component_files(pattern_config, component_type)
                if components:
                    repo_structure[component_type] = components
            else:
                # Archivos simples
                files = process_files(pattern_config, component_type)
                if files:
                    repo_structure[component_type] = files
        
        return repo_structure

    def extract_component_name(self, file_path: Path, component_type: str) -> str:
        """Extrae el nombre del componente del path del archivo"""
        path_parts = Path(file_path).parts
        
        if component_type == 'lwc_components' and 'lwc' in path_parts:
            lwc_index = list(path_parts).index('lwc')
            if lwc_index + 1 < len(path_parts):
                return path_parts[lwc_index + 1]
        
        elif component_type == 'aura_components' and 'aura' in path_parts:
            aura_index = list(path_parts).index('aura')
            if aura_index + 1 < len(path_parts):
                return path_parts[aura_index + 1]
        
        # Fallback: usar nombre del archivo
        return Path(file_path).stem

    def generate_consistent_title(self, repository_data: Dict) -> str:
        """Genera un t√≠tulo consistente basado en el componente principal"""
        
        # Prioridad para identificar componente principal
        priority_components = [
            ('lwc_components', 'LWC'),
            ('apex_classes', 'Apex'),
            ('flows', 'Flow'),
            ('apex_triggers', 'Trigger'),
            ('aura_components', 'Aura'),
            ('objects', 'Object')
        ]
        
        for component_type, prefix in priority_components:
            if component_type in repository_data and repository_data[component_type]:
                
                if component_type in ['lwc_components', 'aura_components']:
                    # Para componentes con subtipos, tomar el primero
                    component_names = list(repository_data[component_type].keys())
                    if component_names:
                        main_component = component_names[0]
                        # FORMATO CONSISTENTE: [Tipo] [Nombre]
                        return f"{prefix} {main_component}"
                else:
                    # Para archivos simples
                    first_file = repository_data[component_type][0]
                    file_name = Path(first_file['path']).stem
                    # FORMATO CONSISTENTE: [Tipo] [Nombre]
                    return f"{prefix} {file_name}"
        
        # Fallback consistente
        return "Salesforce Documentation"

    def search_existing_documentation(self, title: str) -> Optional[str]:
        """Busca documentaci√≥n existente con m√∫ltiples variaciones del t√≠tulo"""
        
        search_url = f"{self.atlassian_base_url}/rest/api/content/search"
        auth = (self.atlassian_email, self.atlassian_api_token)
        
        # Generar variaciones del t√≠tulo para buscar p√°ginas existentes
        title_variations = self.generate_title_variations(title)
        
        print(f"üîç Buscando p√°ginas existentes para: {title}")
        print(f"   Variaciones a buscar: {title_variations}")
        
        for variation in title_variations:
            params = {
                'cql': f'space = "{self.confluence_space_key}" AND type = "page" AND title ~ "{variation}"',
                'limit': 50
            }
            
            try:
                response = requests.get(search_url, auth=auth, params=params)
                if response.status_code == 200:
                    results = response.json()
                    
                    # Buscar coincidencia exacta primero
                    for page in results.get('results', []):
                        if page['title'] == variation:
                            print(f"‚úÖ P√°gina existente encontrada (exacta): {page['title']} (ID: {page['id']})")
                            return page['id']
                    
                    # Si no hay exacta, buscar similar
                    for page in results.get('results', []):
                        page_title_clean = self.normalize_title(page['title'])
                        variation_clean = self.normalize_title(variation)
                        
                        if page_title_clean == variation_clean:
                            print(f"‚úÖ P√°gina existente encontrada (similar): {page['title']} (ID: {page['id']})")
                            return page['id']
                            
            except Exception as e:
                print(f"‚ö†Ô∏è Error buscando '{variation}': {e}")
        
        print(f"‚ÑπÔ∏è No se encontr√≥ documentaci√≥n existente")
        return None

    def generate_title_variations(self, title: str) -> List[str]:
        """Genera todas las variaciones posibles del t√≠tulo para b√∫squeda"""
        
        # Extraer partes del t√≠tulo
        parts = title.split()
        if len(parts) < 2:
            return [title]
        
        component_type = parts[0]  # LWC, Apex, Flow, etc.
        component_name = parts[1]  # languageSelector, etc.
        
        variations = [
            title,  # "LWC languageSelector"
            f"{component_name}",  # "languageSelector"
            f"{component_name} ({component_type})",  # "languageSelector (LWC)"
            f"{component_type} - {component_name}",  # "LWC - languageSelector"
            f"{component_type}_{component_name}",  # "LWC_languageSelector"
            f"{component_name}_{component_type}",  # "languageSelector_LWC"
        ]
        
        return list(set(variations))  # Remover duplicados

    def normalize_title(self, title: str) -> str:
        """Normaliza t√≠tulos para comparaci√≥n"""
        # Convertir a min√∫sculas, remover espacios extra, caracteres especiales
        normalized = title.lower().strip()
        normalized = re.sub(r'[^\w\s]', '', normalized)  # Remover caracteres especiales
        normalized = re.sub(r'\s+', ' ', normalized)  # Espacios √∫nicos
        return normalized

    def call_claude_api(self, repository_data: Dict, main_component: str) -> str:
        """Llama a Claude API para generar documentaci√≥n SUPER completa"""
        
        # Construir contexto del repositorio con TODOS los datos
        repo_context = f"REPOSITORIO SALESFORCE COMPLETO - COMPONENTE PRINCIPAL: {main_component}\n"
        repo_context += "=" * 100 + "\n\n"
        
        total_files = 0
        total_size = 0
        
        for component_type, data in repository_data.items():
            repo_context += f"\n{'#' * 50}\n"
            repo_context += f"## {component_type.upper().replace('_', ' ')}\n"
            repo_context += f"{'#' * 50}\n"
            
            if isinstance(data, dict) and any(isinstance(v, dict) for v in data.values()):
                # Componentes con subtipos (LWC, Aura)
                for component_name, files in data.items():
                    repo_context += f"\n### COMPONENTE: {component_name}\n"
                    for file_type, file_info in files.items():
                        repo_context += f"\n#### {file_type.upper()}: {file_info['path']} ({file_info['size']} chars, {file_info['lines']} lines)\n"
                        repo_context += f"```{self.get_file_extension(file_info['path'])}\n{file_info['content']}\n```\n"
                        total_files += 1
                        total_size += file_info['size']
            else:
                # Archivos simples
                for file_info in data:
                    repo_context += f"\n### ARCHIVO: {file_info['path']} ({file_info['size']} chars, {file_info['lines']} lines)\n"
                    repo_context += f"```{self.get_file_extension(file_info['path'])}\n{file_info['content']}\n```\n"
                    total_files += 1
                    total_size += file_info['size']
        
        repo_context += f"\n\n{'=' * 100}\n"
        repo_context += f"RESUMEN DEL AN√ÅLISIS:\n"
        repo_context += f"- TOTAL ARCHIVOS ANALIZADOS: {total_files}\n"
        repo_context += f"- TOTAL TAMA√ëO C√ìDIGO: {total_size:,} caracteres\n"
        repo_context += f"- COMPONENTE PRINCIPAL IDENTIFICADO: {main_component}\n"
        repo_context += f"- TIPOS DE COMPONENTES: {list(repository_data.keys())}\n"
        repo_context += f"{'=' * 100}\n\n"
        
        # Agregar contexto temporal
        from datetime import datetime
        current_date = datetime.now().strftime("%d/%m/%Y")
        
        # Personalizar el super prompt
        contextualized_prompt = SUPER_DOCUMENTATION_PROMPT.replace('[FECHA_ACTUAL]', current_date)
        contextualized_prompt = contextualized_prompt.replace('[VERSION]', '1.0')
        componentes_lista = []
        for comp_type, data in repository_data.items():
            if isinstance(data, dict) and any(isinstance(v, dict) for v in data.values()):
                componentes_lista.extend([f"{comp_type}:{name}" for name in data.keys()])
            else:
                componentes_lista.append(f"{comp_type}:{len(data)} files")
        
        contextualized_prompt = contextualized_prompt.replace('[LISTA_COMPONENTES_DETALLADA]', ', '.join(componentes_lista))
        
        # Prompt completo
        full_prompt = f"{repo_context}\n\n{contextualized_prompt}"
        
        headers = {
            'Content-Type': 'application/json',
            'x-api-key': self.anthropic_api_key,
            'anthropic-version': '2023-06-01'
        }
        
        payload = {
            'model': 'claude-sonnet-4-20250514',
            'max_tokens': 4000,
            'messages': [
                {
                    'role': 'user',
                    'content': full_prompt
                }
            ]
        }
        
        try:
            print("ü§ñ Generando SUPER documentaci√≥n con Claude API...")
            print(f"üìä Contexto enviado: {len(full_prompt):,} caracteres")
            print(f"üìÅ Archivos analizados: {total_files}")
            print(f"üíæ Tama√±o total c√≥digo: {total_size:,} caracteres")
            
            response = requests.post(
                'https://api.anthropic.com/v1/messages',
                headers=headers,
                json=payload,
                timeout=180  # M√°s tiempo para documentaci√≥n completa
            )
            
            if response.status_code == 200:
                result = response.json()
                documentation = result['content'][0]['text']
                print(f"‚úÖ SUPER documentaci√≥n generada: {len(documentation):,} caracteres")
                return documentation
            else:
                print(f"‚ùå Error en Claude API: {response.status_code}")
                print(response.text)
                return None
                
        except Exception as e:
            print(f"‚ùå Error llamando Claude API: {e}")
            return None

    def get_file_extension(self, file_path: str) -> str:
        """Obtiene la extensi√≥n del archivo para syntax highlighting"""
        extension_map = {
            '.cls': 'apex',
            '.trigger': 'apex', 
            '.js': 'javascript',
            '.html': 'html',
            '.css': 'css',
            '.xml': 'xml',
            '.cmp': 'xml',
            '.page': 'html',
            '.component': 'html'
        }
        
        suffix = Path(file_path).suffix
        return extension_map.get(suffix, 'text')

    def run(self):
        """Ejecuta el proceso completo de generaci√≥n de SUPER documentaci√≥n"""
        
        print("üöÄ Iniciando generaci√≥n de SUPER DOCUMENTACI√ìN Salesforce v3.0")
        print("=" * 80)
        
        # 1. An√°lisis completo del repositorio
        print("\nüìÅ Paso 1: An√°lisis COMPLETO del repositorio Salesforce...")
        repository_data = self.analyze_salesforce_repository()
        
        if not repository_data:
            print("‚ö†Ô∏è No se encontraron archivos Salesforce en el repositorio")
            return False
        
        # 2. Generar t√≠tulo consistente
        print("\nüéØ Paso 2: Generando t√≠tulo CONSISTENTE...")
        consistent_title = self.generate_consistent_title(repository_data)
        print(f"‚úÖ T√≠tulo consistente: '{consistent_title}'")
        
        # Mostrar estad√≠sticas
        total_files = 0
        for comp_type, data in repository_data.items():
            if isinstance(data, dict) and any(isinstance(v, dict) for v in data.values()):
                count = len(data)
                total_files += sum(len(files) for files in data.values())
                print(f"   - {comp_type}: {count} componentes")
            else:
                count = len(data)
                total_files += count
                print(f"   - {comp_type}: {count} archivos")
        
        print(f"üìä TOTAL: {total_files} archivos a documentar")
        
        # 3. Buscar documentaci√≥n existente con m√∫ltiples variaciones
        print("\nüîç Paso 3: Buscando documentaci√≥n existente...")
        existing_page_id = self.search_existing_documentation(consistent_title)
        
        # 4. Generar SUPER documentaci√≥n
        print("\nü§ñ Paso 4: Generando SUPER documentaci√≥n completa...")
        documentation = self.call_claude_api(repository_data, consistent_title)
        
        if not documentation:
            print("‚ùå Error generando documentaci√≥n")
            return False
        
        # 5. Limpiar t√≠tulo de la documentaci√≥n generada
        final_title = self.clean_documentation_title(documentation, consistent_title)
        print(f"üìã T√≠tulo final: '{final_title}'")
        
        # 6. Crear o actualizar con t√≠tulo consistente
        print("\nüìù Paso 5: Publicando en Confluence...")
        
        if existing_page_id:
            success = self.update_confluence_page(existing_page_id, final_title, documentation)
            print("üîÑ Documentaci√≥n ACTUALIZADA")
        else:
            success = self.create_confluence_page(final_title, documentation)
            print("üÜï Nueva documentaci√≥n CREADA")
        
        if success:
            print("\nüéâ ¬°SUPER documentaci√≥n completada exitosamente!")
            print(f"üìä Confluence Space: {self.confluence_space_key}")
            print(f"üìÑ P√°gina: '{final_title}'")
            print(f"üéØ Componente Principal: {consistent_title}")
            print(f"üìÅ Total Archivos Documentados: {total_files}")
            return True
        else:
            print("\n‚ùå Error en el proceso de publicaci√≥n")
            return False

    def clean_documentation_title(self, documentation: str, fallback_title: str) -> str:
        """Limpia y normaliza el t√≠tulo extra√≠do de la documentaci√≥n"""
        
        # Buscar primer H1 en la documentaci√≥n
        match = re.search(r'^# (.+?)$', documentation, re.MULTILINE)
        if match:
            title = match.group(1).strip()
            # Limpiar emojis y caracteres especiales 
            title = re.sub(r'[üéØüèóÔ∏èüì¶üíª‚ö†Ô∏èüîßüìäüöÄ‚ö°üîíüîóüé®üìäüì±üîÑüåêüîç]', '', title).strip()
            # Limpiar corchetes y contenido
            title = re.sub(r'\[.*?\]', '', title).strip()
            
            if title and len(title) > 3:  # T√≠tulo v√°lido
                return title
        
        # Usar t√≠tulo consistente como fallback
        return fallback_title

    # Resto de m√©todos (mantener los existentes)
    def search_confluence_page(self, title: str) -> Optional[str]:
        """Busca si existe una p√°gina en Confluence con el t√≠tulo dado"""
        
        search_url = f"{self.atlassian_base_url}/rest/api/content"
        auth = (self.atlassian_email, self.atlassian_api_token)
        
        params = {
            'type': 'page',
            'spaceKey': self.confluence_space_key,
            'title': title,
            'expand': 'version'
        }
        
        try:
            response = requests.get(search_url, auth=auth, params=params)
            
            if response.status_code == 200:
                results = response.json()
                if results['results']:
                    page_id = results['results'][0]['id']
                    print(f"‚úÖ P√°gina existente encontrada: {title} (ID: {page_id})")
                    return page_id
                else:
                    print(f"‚ÑπÔ∏è No existe p√°gina con t√≠tulo: {title}")
                    return None
            else:
                print(f"‚ö†Ô∏è Error buscando p√°gina: {response.status_code}")
                return None
                
        except Exception as e:
            print(f"‚ùå Error en b√∫squeda Confluence: {e}")
            return None

    def create_confluence_page(self, title: str, content: str) -> bool:
        """Crea una nueva p√°gina en Confluence"""
        
        create_url = f"{self.atlassian_base_url}/rest/api/content"
        auth = (self.atlassian_email, self.atlassian_api_token)
        
        confluence_content = self.markdown_to_confluence_storage(content)
        
        payload = {
            'type': 'page',
            'title': title,
            'space': {'key': self.confluence_space_key},
            'body': {
                'storage': {
                    'value': confluence_content,
                    'representation': 'storage'
                }
            }
        }
        
        headers = {'Content-Type': 'application/json'}
        
        try:
            response = requests.post(create_url, auth=auth, headers=headers, json=payload)
            
            if response.status_code == 200:
                result = response.json()
                page_id = result['id']
                page_url = f"{self.atlassian_base_url}/pages/viewpage.action?pageId={page_id}"
                print(f"‚úÖ Nueva p√°gina creada: {title}")
                print(f"üîó URL: {page_url}")
                return True
            else:
                print(f"‚ùå Error creando p√°gina: {response.status_code}")
                print(response.text)
                return False
                
        except Exception as e:
            print(f"‚ùå Error creando p√°gina en Confluence: {e}")
            return False

    def update_confluence_page(self, page_id: str, title: str, content: str) -> bool:
        """Actualiza una p√°gina existente en Confluence"""
        
        get_url = f"{self.atlassian_base_url}/rest/api/content/{page_id}"
        auth = (self.atlassian_email, self.atlassian_api_token)
        
        params = {'expand': 'version'}
        
        try:
            response = requests.get(get_url, auth=auth, params=params)
            
            if response.status_code != 200:
                print(f"‚ùå Error obteniendo p√°gina: {response.status_code}")
                return False
            
            page_data = response.json()
            current_version = page_data['version']['number']
            
            update_url = f"{self.atlassian_base_url}/rest/api/content/{page_id}"
            confluence_content = self.markdown_to_confluence_storage(content)
            
            payload = {
                'version': {'number': current_version + 1},
                'title': title,
                'type': 'page',
                'body': {
                    'storage': {
                        'value': confluence_content,
                        'representation': 'storage'
                    }
                }
            }
            
            headers = {'Content-Type': 'application/json'}
            
            response = requests.put(update_url, auth=auth, headers=headers, json=payload)
            
            if response.status_code == 200:
                page_url = f"{self.atlassian_base_url}/pages/viewpage.action?pageId={page_id}"
                print(f"‚úÖ P√°gina actualizada: {title}")
                print(f"üîó URL: {page_url}")
                print(f"üìä Versi√≥n: {current_version} ‚Üí {current_version + 1}")
                return True
            else:
                print(f"‚ùå Error actualizando p√°gina: {response.status_code}")
                print(response.text)
                return False
                
        except Exception as e:
            print(f"‚ùå Error actualizando p√°gina en Confluence: {e}")
            return False

    def markdown_to_confluence_storage(self, markdown_content: str) -> str:
        """Convierte markdown a Confluence Storage Format con mejor soporte"""
        
        content = markdown_content
        
        # Headers con mejor manejo
        content = re.sub(r'^# (.*?)$', r'<h1>\1</h1>', content, flags=re.MULTILINE)
        content = re.sub(r'^## (.*?)$', r'<h2>\1</h2>', content, flags=re.MULTILINE)
        content = re.sub(r'^### (.*?)$', r'<h3>\1</h3>', content, flags=re.MULTILINE)
        content = re.sub(r'^#### (.*?)$', r'<h4>\1</h4>', content, flags=re.MULTILINE)
        
        # Bold and italic
        content = re.sub(r'\*\*(.*?)\*\*', r'<strong>\1</strong>', content)
        content = re.sub(r'\*(.*?)\*', r'<em>\1</em>', content)
        
        # Tables - mejor conversi√≥n
        content = self.convert_markdown_tables(content)
        
        # Code blocks con mejor manejo de lenguajes
        content = re.sub(
            r'```(\w+)?\n(.*?)\n```', 
            lambda m: f'<ac:structured-macro ac:name="code"><ac:parameter ac:name="language">{m.group(1) or "text"}</ac:parameter><ac:plain-text-body><![CDATA[{m.group(2)}]]></ac:plain-text-body></ac:structured-macro>', 
            content, 
            flags=re.DOTALL
        )
        
        # Inline code
        content = re.sub(r'`(.*?)`', r'<code>\1</code>', content)
        
        # Lists con mejor estructura
        content = self.convert_markdown_lists(content)
        
        # Mermaid diagrams
        content = re.sub(
            r'```mermaid\n(.*?)\n```',
            r'<ac:structured-macro ac:name="mermaid"><ac:plain-text-body><![CDATA[\1]]></ac:plain-text-body></ac:structured-macro>',
            content,
            flags=re.DOTALL
        )
        
        # Links
        content = re.sub(r'\[([^\]]+)\]\(([^\)]+)\)', r'<a href="\2">\1</a>', content)
        
        # Line breaks
        content = content.replace('\n', '<br/>')
        
        return content

    def convert_markdown_tables(self, content: str) -> str:
        """Convierte tablas markdown a formato Confluence"""
        
        def table_replacer(match):
            lines = match.group(0).strip().split('\n')
            if len(lines) < 2:
                return match.group(0)
            
            # Header
            headers = [cell.strip() for cell in lines[0].split('|')[1:-1]]
            
            # Skip separator line
            data_lines = lines[2:]
            
            table_html = '<table><thead><tr>'
            for header in headers:
                table_html += f'<th>{header}</th>'
            table_html += '</tr></thead><tbody>'
            
            for line in data_lines:
                if line.strip():
                    cells = [cell.strip() for cell in line.split('|')[1:-1]]
                    table_html += '<tr>'
                    for cell in cells:
                        table_html += f'<td>{cell}</td>'
                    table_html += '</tr>'
            
            table_html += '</tbody></table>'
            return table_html
        
        # Pattern para detectar tablas markdown
        table_pattern = r'\|.*?\|\n\|[-\s|:]+\|\n(?:\|.*?\|\n)+'
        content = re.sub(table_pattern, table_replacer, content, flags=re.MULTILINE)
        
        return content

    def convert_markdown_lists(self, content: str) -> str:
        """Convierte listas markdown a formato Confluence"""
        
        # Listas con bullets
        content = re.sub(r'^- (.*?)$', r'<ul><li>\1</li></ul>', content, flags=re.MULTILINE)
        
        # Listas numeradas  
        content = re.sub(r'^\d+\. (.*?)$', r'<ol><li>\1</li></ol>', content, flags=re.MULTILINE)
        
        # Consolidar listas consecutivas
        content = re.sub(r'</ul><br/><ul>', '', content)
        content = re.sub(r'</ol><br/><ol>', '', content)
        
        return content

if __name__ == "__main__":
    generator = SuperSalesforceDocumentationGenerator()
    success = generator.run()
    sys.exit(0 if success else 1)